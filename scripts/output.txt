[ DPDK EAL parameters: hello_world -l 0,1,2,3,4 -m 4096 --no-telemetry --log-level=lib.eal:6 --log-level=lib.cryptodev:5 --log-level=user1:6 --iova-mode=pa --base-virtaddr=0x200000000000 --match-allocations --file-prefix=spdk114514 --proc-type=auto ]
probe device!
gpu shared library inited!
probe device!
probe device!
probe device!
0 Attached to 0000:c3:00.0
  Namespace ID: 1 size: 400GB
0 Attached to 0000:c2:00.0
  Namespace ID: 1 size: 400GB
0 Attached to 0000:c4:00.0
  Namespace ID: 1 size: 400GB
0 Attached to 0000:c5:00.0
  Namespace ID: 1 size: 400GB
lam: 0.02
Creating new worker on GPU 0 at time 1718282475.8331225
{'type': 'request_sent', 'request_id': 0, 'time': 1718282475.834128}
INFO 06-13 20:41:15 llm_engine.py:107] Initializing an LLM engine with config: model='/home/zsx/raidfs-back/home/zsx/.cache/huggingface/hub/models--openlm-research--open_llama_13b/snapshots/b6d7fde8392250730d24cc2fcfa3b7e5f9a03ce8/', time=1718282475.8613927, tokenizer='/home/zsx/raidfs-back/home/zsx/.cache/huggingface/hub/models--openlm-research--open_llama_13b/snapshots/b6d7fde8392250730d24cc2fcfa3b7e5f9a03ce8/', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0, log_stats=True, fast_start=True, persist_cudagraph=True, load_graph=True, batch_size=0, model_name=Llama-13B, async_load=True, log=None, save_tensor=False, batch_step=-1
Initializing async load threads...
[ DPDK EAL parameters: hello_world -l 0,1,2,3,4 -m 4096 --no-telemetry --log-level=lib.eal:6 --log-level=lib.cryptodev:5 --log-level=user1:6 --iova-mode=pa --base-virtaddr=0x200000000000 --match-allocations --file-prefix=spdk114514 --proc-type=auto ]
probe device!
probe device!
probe device!
probe device!
probe device!
probe device!
probe device!
probe device!
0 Attached to 0000:c3:00.0
  Namespace ID: 1 size: 400GB
0 Attached to 0000:c2:00.0
  Namespace ID: 1 size: 400GB
0 Attached to 0000:c4:00.0
  Namespace ID: 1 size: 400GB
0 Attached to 0000:c5:00.0
  Namespace ID: 1 size: 400GB
cpu_buffer 0x2000fdc00000, error no error
{'type': 'request_sent', 'request_id': 1, 'time': 1718282476.6731017}
cpu_buffer 0x2000bda00000, error no error
cpu_buffer 0x20007d800000, error no error
INFO 06-13 20:41:16 llm_engine.py:455] # GPU blocks: 512, # CPU blocks: 512
Start loading tensors...
cpu_buffer 0x200180000000, error no error
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
INFO 06-13 20:41:17 model_runner.py:711] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 06-13 20:41:17 model_runner.py:715] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Waiting for async load threads to finish...
{'type': 'request_sent', 'request_id': 2, 'time': 1718282477.7381427}
warm up model finish
early return......
load_cuda_graph Duration: 0.00241926 seconds
modified result hidden_states addr cuda:0 0x7d3263000000 torch.Size([256, 1, 5120])
early return......
load_cuda_graph Duration: 0.00231087 seconds
modified result hidden_states addr cuda:0 0x7d32634ec000 torch.Size([248, 1, 5120])
early return......
load_cuda_graph Duration: 0.00240373 seconds
modified result hidden_states addr cuda:0 0x7d35874a8000 torch.Size([240, 1, 5120])
early return......
load_cuda_graph Duration: 0.00232157 seconds
modified result hidden_states addr cuda:0 0x7d326389e000 torch.Size([232, 1, 5120])
early return......
load_cuda_graph Duration: 0.0023132 seconds
modified result hidden_states addr cuda:0 0x7d3587930000 torch.Size([224, 1, 5120])
early return......
load_cuda_graph Duration: 0.00239669 seconds
modified result hidden_states addr cuda:0 0x7d35b1020000 torch.Size([216, 1, 5120])
early return......
load_cuda_graph Duration: 0.00241126 seconds
modified result hidden_states addr cuda:0 0x7d3263b90000 torch.Size([208, 1, 5120])
early return......
load_cuda_graph Duration: 0.00244918 seconds
modified result hidden_states addr cuda:0 0x7d35b123c000 torch.Size([200, 1, 5120])
early return......
load_cuda_graph Duration: 0.00243216 seconds
modified result hidden_states addr cuda:0 0x7d3263280000 torch.Size([192, 1, 5120])
early return......
load_cuda_graph Duration: 0.00241646 seconds
modified result hidden_states addr cuda:0 0x7d3263280000 torch.Size([184, 1, 5120])
early return......
load_cuda_graph Duration: 0.0022948 seconds
modified result hidden_states addr cuda:0 0x7d3263280000 torch.Size([176, 1, 5120])
early return......
load_cuda_graph Duration: 0.00236184 seconds
modified result hidden_states addr cuda:0 0x7d3263280000 torch.Size([168, 1, 5120])
early return......
load_cuda_graph Duration: 0.00231354 seconds
modified result hidden_states addr cuda:0 0x7d3263410000 torch.Size([160, 1, 5120])
early return......
load_cuda_graph Duration: 0.00229724 seconds
modified result hidden_states addr cuda:0 0x7d326371c000 torch.Size([152, 1, 5120])
early return......
load_cuda_graph Duration: 0.00232106 seconds
modified result hidden_states addr cuda:0 0x7d3587700000 torch.Size([144, 1, 5120])
early return......
load_cuda_graph Duration: 0.0022984 seconds
modified result hidden_states addr cuda:0 0x7d35b17c6000 torch.Size([136, 1, 5120])
early return......
load_cuda_graph Duration: 0.00239974 seconds
modified result hidden_states addr cuda:0 0x7d35b1ac0000 torch.Size([128, 1, 5120])
early return......
load_cuda_graph Duration: 0.00236065 seconds
modified result hidden_states addr cuda:0 0x7d3263280000 torch.Size([120, 1, 5120])
early return......
load_cuda_graph Duration: 0.00235463 seconds
modified result hidden_states addr cuda:0 0x7d32635a0000 torch.Size([112, 1, 5120])
early return......
load_cuda_graph Duration: 0.00234073 seconds
modified result hidden_states addr cuda:0 0x7d35b1534000 torch.Size([104, 1, 5120])
early return......
load_cuda_graph Duration: 0.00238304 seconds
modified result hidden_states addr cuda:0 0x7d3263ef0000 torch.Size([96, 1, 5120])
early return......
load_cuda_graph Duration: 0.00231322 seconds
modified result hidden_states addr cuda:0 0x7d3281400000 torch.Size([88, 1, 5120])
early return......
load_cuda_graph Duration: 0.00232032 seconds
modified result hidden_states addr cuda:0 0x7d32814dc000 torch.Size([80, 1, 5120])
early return......
load_cuda_graph Duration: 0.00235601 seconds
modified result hidden_states addr cuda:0 0x7d3281a00000 torch.Size([72, 1, 5120])
early return......
load_cuda_graph Duration: 0.00256853 seconds
modified result hidden_states addr cuda:0 0x7d3281b54000 torch.Size([64, 1, 5120])
early return......
load_cuda_graph Duration: 0.00244657 seconds
modified result hidden_states addr cuda:0 0x7d3287400000 torch.Size([56, 1, 5120])
early return......
load_cuda_graph Duration: 0.00245169 seconds
modified result hidden_states addr cuda:0 0x7d3263e78000 torch.Size([48, 1, 5120])
early return......
load_cuda_graph Duration: 0.0024461 seconds
modified result hidden_states addr cuda:0 0x7d3281ab4000 torch.Size([40, 1, 5120])
early return......
load_cuda_graph Duration: 0.00243529 seconds
modified result hidden_states addr cuda:0 0x7d3263e00000 torch.Size([32, 1, 5120])
early return......
load_cuda_graph Duration: 0.00229812 seconds
modified result hidden_states addr cuda:0 0x7d3287400000 torch.Size([24, 1, 5120])
early return......
load_cuda_graph Duration: 0.00270658 seconds
modified result hidden_states addr cuda:0 0x7d32815cc000 torch.Size([16, 1, 5120])
early return......
load_cuda_graph Duration: 0.00299744 seconds
modified result hidden_states addr cuda:0 0x7d3263e64000 torch.Size([8, 1, 5120])
early return......
load_cuda_graph Duration: 0.0028238 seconds
modified result hidden_states addr cuda:0 0x7d3263e5a000 torch.Size([4, 1, 5120])
early return......
load_cuda_graph Duration: 0.00274509 seconds
modified result hidden_states addr cuda:0 0x7d3263ffb000 torch.Size([2, 1, 5120])
early return......
load_cuda_graph Duration: 0.00296025 seconds
modified result hidden_states addr cuda:0 0x7d3263e52800 torch.Size([1, 1, 5120])
INFO 06-13 20:41:18 model_runner.py:805] Graph capturing finished in 252 millisecs.
Worker 0 started
Waiting for async load threads to finish...
{'type': 'request', 'payload': (124, 1363), 'request_id': 0}
{'type': 'request', 'payload': (7, 512), 'request_id': 1}
{'type': 'request', 'payload': (149, 563), 'request_id': 2}
{'type': 'request_sent', 'request_id': 3, 'time': 1718282479.0131364}
{'type': 'first_time', 'data': 1718282478.3937306, 'request_id': 0}
{'type': 'first_time', 'data': 1718282478.41886, 'request_id': 1}
{'type': 'first_time', 'data': 1718282478.4517725, 'request_id': 2}
{'type': 'request_sent', 'request_id': 4, 'time': 1718282479.5222185}
{'type': 'request_sent', 'request_id': 5, 'time': 1718282479.5581546}
{'type': 'request_sent', 'request_id': 6, 'time': 1718282479.8536956}
{'type': 'request_sent', 'request_id': 7, 'time': 1718282480.06632}
{'type': 'request_sent', 'request_id': 8, 'time': 1718282480.2430422}
{'type': 'request_sent', 'request_id': 9, 'time': 1718282480.3630412}
{'type': 'request_sent', 'request_id': 10, 'time': 1718282480.3631423}
{'type': 'request_sent', 'request_id': 11, 'time': 1718282481.6432018}
{'type': 'request_sent', 'request_id': 12, 'time': 1718282481.7730622}
{'type': 'request_sent', 'request_id': 13, 'time': 1718282482.0630445}
{'type': 'request_sent', 'request_id': 14, 'time': 1718282483.1031058}
{'type': 'request_sent', 'request_id': 15, 'time': 1718282483.4630446}
Creating new worker on GPU 1 at time 1718282484.3030276
{'type': 'request_sent', 'request_id': 16, 'time': 1718282484.3034585}
INFO 06-13 20:41:24 llm_engine.py:107] Initializing an LLM engine with config: model='/home/zsx/raidfs-back/home/zsx/.cache/huggingface/hub/models--openlm-research--open_llama_13b/snapshots/b6d7fde8392250730d24cc2fcfa3b7e5f9a03ce8/', time=1718282484.3259654, tokenizer='/home/zsx/raidfs-back/home/zsx/.cache/huggingface/hub/models--openlm-research--open_llama_13b/snapshots/b6d7fde8392250730d24cc2fcfa3b7e5f9a03ce8/', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0, log_stats=True, fast_start=True, persist_cudagraph=True, load_graph=True, batch_size=0, model_name=Llama-13B, async_load=True, log=None, save_tensor=False, batch_step=-1
Initializing async load threads...
[ DPDK EAL parameters: hello_world -l 0,1,2,3,4 -m 4096 --no-telemetry --log-level=lib.eal:6 --log-level=lib.cryptodev:5 --log-level=user1:6 --iova-mode=pa --base-virtaddr=0x200000000000 --match-allocations --file-prefix=spdk114514 --proc-type=auto ]
{'type': 'request_sent', 'request_id': 17, 'time': 1718282485.08315}
probe device!
probe device!
probe device!
probe device!
probe device!
probe device!
probe device!
probe device!
0 Attached to 0000:c3:00.0
  Namespace ID: 1 size: 400GB
0 Attached to 0000:c2:00.0
  Namespace ID: 1 size: 400GB
0 Attached to 0000:c4:00.0
  Namespace ID: 1 size: 400GB
0 Attached to 0000:c5:00.0
  Namespace ID: 1 size: 400GB
INFO 06-13 20:41:25 llm_engine.py:455] # GPU blocks: 512, # CPU blocks: 512
Start loading tensors...
cpu_buffer 0x200200000000, error no error
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
{'type': 'request_sent', 'request_id': 18, 'time': 1718282485.5132184}
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
early return......
{'type': 'request_sent', 'request_id': 19, 'time': 1718282485.57415}
{'type': 'request_sent', 'request_id': 20, 'time': 1718282485.6942282}
cpu_buffer 0x200280000000, error no error
{'type': 'request_sent', 'request_id': 21, 'time': 1718282485.8222039}
INFO 06-13 20:41:25 model_runner.py:711] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 06-13 20:41:25 model_runner.py:715] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Waiting for async load threads to finish...
{'type': 'request_sent', 'request_id': 22, 'time': 1718282485.9630425}
cpu_buffer 0x200300000000, error no error
cpu_buffer 0x200380000000, error no error
{'type': 'request_sent', 'request_id': 23, 'time': 1718282486.6230469}
{'type': 'request_sent', 'request_id': 24, 'time': 1718282486.9941545}
warm up model finish
early return......
load_cuda_graph Duration: 0.00242398 seconds
modified result hidden_states addr cuda:0 0x73777f000000 torch.Size([256, 1, 5120])
early return......
load_cuda_graph Duration: 0.00229573 seconds
modified result hidden_states addr cuda:0 0x73777f4ec000 torch.Size([248, 1, 5120])
early return......
load_cuda_graph Duration: 0.00244259 seconds
modified result hidden_states addr cuda:0 0x737aa34a8000 torch.Size([240, 1, 5120])
early return......
load_cuda_graph Duration: 0.00232154 seconds
modified result hidden_states addr cuda:0 0x73777f89e000 torch.Size([232, 1, 5120])
early return......
load_cuda_graph Duration: 0.00234817 seconds
modified result hidden_states addr cuda:0 0x737aa3930000 torch.Size([224, 1, 5120])
early return......
load_cuda_graph Duration: 0.00234615 seconds
modified result hidden_states addr cuda:0 0x737acd020000 torch.Size([216, 1, 5120])
early return......
load_cuda_graph Duration: 0.00242631 seconds
modified result hidden_states addr cuda:0 0x73777fb90000 torch.Size([208, 1, 5120])
early return......
load_cuda_graph Duration: 0.00242618 seconds
modified result hidden_states addr cuda:0 0x737acd23c000 torch.Size([200, 1, 5120])
early return......
load_cuda_graph Duration: 0.00239781 seconds
modified result hidden_states addr cuda:0 0x73777f280000 torch.Size([192, 1, 5120])
early return......
load_cuda_graph Duration: 0.0024362 seconds
modified result hidden_states addr cuda:0 0x73777f280000 torch.Size([184, 1, 5120])
early return......
load_cuda_graph Duration: 0.00229874 seconds
modified result hidden_states addr cuda:0 0x73777f280000 torch.Size([176, 1, 5120])
